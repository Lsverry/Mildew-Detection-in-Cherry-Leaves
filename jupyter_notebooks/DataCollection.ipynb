{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Data Collection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Fetch data from Kaggle's cherry leaf dataset and prepare it for further analysis and model development.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Kaggle API Key: A JSON file with the authentication token to access the Kaggle dataset.\n",
        "* Kaggle Dataset ID: The specific ID for the cherry leaf dataset on Kaggle. \n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Generated Dataset: The images of cherry leaves (both healthy and infected) saved in the inputs/cherry_leaves directory. \n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* No additional comments at this stage.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os  # Library for interacting with the operating system\n",
        "import shutil  # Used for high-level file operations like moving and copying files\n",
        "import random  # To shuffle data for random splits between training, validation, and test sets\n",
        "import zipfile  # For extracting files from zip archives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "## Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/Mildew-Detection-in-Cherry-Leaves/jupyter_notebooks'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/Mildew-Detection-in-Cherry-Leaves'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "## Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Change Kaggle configuration directory to the current working directory and set permission for kaggle.json\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
        "! chmod 600 kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/codeinstitute/cherry-leaves\n",
            "License(s): unknown\n",
            "Downloading cherry-leaves.zip to inputs\n",
            " 93%|███████████████████████████████████▏  | 51.0M/55.0M [00:05<00:00, 7.29MB/s]\n",
            "100%|██████████████████████████████████████| 55.0M/55.0M [00:05<00:00, 10.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Set destination folder\n",
        "\n",
        "KaggleDatasetPath = \"codeinstitute/cherry-leaves\"  \n",
        "DestinationFolder = \"inputs\"\n",
        "!kaggle datasets download -d {KaggleDatasetPath} -p {DestinationFolder}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Unzip the downloaded file and delete the zip file to save space\n",
        "with zipfile.ZipFile(DestinationFolder + '/cherry-leaves.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall(DestinationFolder)\n",
        "\n",
        "os.remove(DestinationFolder + '/cherry-leaves.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Remove non-image files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data cleaning complete. Non-image files removed.\n"
          ]
        }
      ],
      "source": [
        "def clean_non_image_files(data_dir):\n",
        "    \"\"\"\n",
        "    This function removes non-image files from the dataset directories.\n",
        "    Only .png, .jpg, and .jpeg files are kept.\n",
        "    \"\"\"\n",
        "    allowed_extensions = ('.png', '.jpg', '.jpeg')\n",
        "    \n",
        "    # Loop through the folders inside the data directory\n",
        "    for folder in os.listdir(data_dir):\n",
        "        folder_path = os.path.join(data_dir, folder)\n",
        "        \n",
        "        if os.path.isdir(folder_path):\n",
        "            files_in_folder = os.listdir(folder_path)\n",
        "            \n",
        "    \n",
        "            non_image_files = [file for file in files_in_folder if not file.lower().endswith(allowed_extensions)]\n",
        "            \n",
        "            for non_image_file in non_image_files:\n",
        "                file_path = os.path.join(folder_path, non_image_file)\n",
        "                os.remove(file_path)  # Remove the non-image file\n",
        "                print(f\"Removed: {file_path}\")\n",
        "    \n",
        "    print(\"Data cleaning complete. Non-image files removed.\")\n",
        "\n",
        "# Specify the directory where the cherry leaf images are stored\n",
        "clean_non_image_files('inputs/cherry-leaves')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Split dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset has been successfully split into train, validation, and test sets.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def organize_dataset(data_directory, train_split=0.7, validation_split=0.1, test_split=0.2):\n",
        "    \"\"\"\n",
        "    Organizes the dataset into training, validation, and test sets.\n",
        "    The function creates folders for each split and moves files accordingly.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Ensure the ratios sum to 1\n",
        "    if not abs((train_split + validation_split + test_split) - 1.0) < 1e-6:\n",
        "        raise ValueError(\"The splits must sum to 1.0\")\n",
        "    \n",
        "    # Identify class directories (healthy/infected)\n",
        "    categories = [category for category in os.listdir(data_directory) if os.path.isdir(os.path.join(data_directory, category))]\n",
        "    \n",
        "    # Create necessary folders for train, validation, and test splits\n",
        "    for split in ['train', 'validation', 'test']:\n",
        "        for category in categories:\n",
        "            split_path = os.path.join(data_directory, split, category)\n",
        "            os.makedirs(split_path, exist_ok=True)\n",
        "    \n",
        "    # Move images to their respective split directories\n",
        "    for category in categories:\n",
        "        category_path = os.path.join(data_directory, category)\n",
        "        images = os.listdir(category_path)\n",
        "        random.shuffle(images)  # Shuffle to ensure random distribution\n",
        "        \n",
        "        # Calculate the number of images for each split\n",
        "        train_size = int(len(images) * train_split)\n",
        "        validation_size = int(len(images) * validation_split)\n",
        "        \n",
        "        # Move images to training set\n",
        "        for image in images[:train_size]:\n",
        "            src = os.path.join(category_path, image)\n",
        "            dst = os.path.join(data_directory, 'train', category, image)\n",
        "            shutil.move(src, dst)\n",
        "        \n",
        "        # Move images to validation set\n",
        "        for image in images[train_size:train_size + validation_size]:\n",
        "            src = os.path.join(category_path, image)\n",
        "            dst = os.path.join(data_directory, 'validation', category, image)\n",
        "            shutil.move(src, dst)\n",
        "        \n",
        "        # Move remaining images to test set\n",
        "        for image in images[train_size + validation_size:]:\n",
        "            src = os.path.join(category_path, image)\n",
        "            dst = os.path.join(data_directory, 'test', category, image)\n",
        "            shutil.move(src, dst)\n",
        "\n",
        "    print(\"Dataset has been successfully split into train, validation, and test sets.\")\n",
        "\n",
        "# Execute the function with the cherry leaves dataset\n",
        "organize_dataset(data_directory=\"inputs/cherry-leaves\", train_split=0.7, validation_split=0.1, test_split=0.2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusions\n",
        "* The dataset from Kaggle containing images of healthy and powdery mildew-infected cherry leaves has been successfully downloaded and organized.\n",
        "* Non-image files were cleaned from the dataset to ensure the integrity of the image classification process.\n",
        "* The data was split into training, validation, and test sets, adhering to the 70/10/20 ratio. This split will allow for robust model training and performance evaluation."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
